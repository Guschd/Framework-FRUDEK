# M14 â€“ Validierung & QualitÃ¤tssicherung

## ğŸ§­ Zielsetzung

M14 stellt die Werkzeuge, Methoden und Richtlinien zur VerfÃ¼gung, mit denen Inhalte, Antworten und Entscheidungen innerhalb des FRUDEK-Systems auf ihre **Richtigkeit, Konsistenz und ZuverlÃ¤ssigkeit** geprÃ¼ft werden.

Dieses Modul zielt darauf ab, **Vertrauen durch wiederholbare PrÃ¼fverfahren, Feedback-Integration und technische Validierungsprozesse** zu stÃ¤rken â€“ sowohl fÃ¼r menschliche als auch KI-generierte BeitrÃ¤ge.

---

## âœ… Anwendungsfelder

- PrÃ¼fung der AntwortqualitÃ¤t (inhaltlich, formal, ethisch)
- RÃ¼ckverfolgbarkeit von Entscheidungen und Antwortwegen
- Double-Check durch kontrollierte Gegenfragen oder Eskalationspfade
- QualitÃ¤tssicherung durch Feedbacksysteme oder Peer-Review
- Einsatz in Pilotstudien, Modultests, Prompt-Tests

---

## ğŸ§° Tools & Techniken

| Tool / Verfahren | Einsatzbereich | Bemerkung |
|------------------|----------------|-----------|
| ğŸ”„ RedundanzprÃ¼fung | semantisch Ã¤hnliche Prompts testen | erkennt Inkonsistenzen |
| ğŸ§ª Double Prompting | zwei Varianten generieren & vergleichen | erhÃ¶ht Sicherheit |
| ğŸ¤ Peer Review (Mensch â†” KI) | bei kritischen Inhalten / Studien | Vertrauen durch Transparenz |
| ğŸ“Š BewertungsbÃ¶gen | standardisierte Feedbackformulare | auch fÃ¼r Studien geeignet |
| ğŸ§  Logfile-Analyse | technische Validierung von Antwortverhalten | z.â€¯B. bei API-Tests |
| ğŸ§¾ PrÃ¼flisten / Checklisten | manuelle QS fÃ¼r sensitive Usecases | z.â€¯B. medizinische, juristische Anfragen |

---

## ğŸ§ª Testfall-Cluster

### âœ… Testfall A

**Frage:** â€Warum kommen bei gleicher Frage unterschiedliche Antworten?â€œ

**Analyse:** RedundanzprÃ¼fung (verschiedene Nutzer, gleiches Thema). Unterschiede durch Framing (M12) oder tagesaktuelle Wissensbasis.

**QS-MaÃŸnahme:** Antwortvergleiche loggen, Version annotieren, AuslÃ¶ser klÃ¤ren.

---

### âœ… Testfall B

**Frage:** â€Kann ich mich auf die Antwort verlassen? Ich muss das in meiner Bachelorarbeit zitieren.â€œ

**LÃ¶sung:**  
â†’ Modul 9 (Attribution) + Modul 14 â†’ QualitÃ¤tssicherungskennzeichnung  
â†’ Vorschlag: Metadaten-Export + optionaler Vermerk: *nicht peer-reviewed*

---

### âœ… Testfall C

**Kontext:** Zwei KI-Antworten liefern unterschiedliche technische Pfade (z.â€¯B. zur Serverdiagnose)

**QS-Schritte:**

- Replikation der Testbedingungen
- Extraktion der relevanten Module (z.â€¯B. M2, M4, M6)
- RÃ¼ckfrage an Nutzer: â€Welche Konfiguration bestand genau?â€œ
- Nachtest mit simulierter Umgebung

---

## ğŸ“Œ Metadaten & Kontrollfelder

In alle qualitÃ¤tsrelevanten Ausgaben kÃ¶nnen folgende Felder eingebettet werden:

```yaml
quality_check: passed
confidence_level: 0.92
peer_reviewed: false
last_validated: 2025-08-07
validator: GPT-4o / SB


ğŸ”„ Feedbackzyklen


Eingebettet in Studienprojekte (z.â€¯B. bei Modultests)
Eskalation an Kontrollinstanz bei widersprÃ¼chlichen Ergebnissen
MÃ¶glichkeit zur RÃ¼ckmeldung durch Nutzer (SchaltflÃ¤che oder Prompt)





ğŸ”— Verbindungen


verwendet durch: M1â€“M13 (inhaltliche Validierung)
besonders relevant fÃ¼r:â€¨
M9 (Attribution)
M12 (Framing)
M11 (technische Fehlerbilder)

âš ï¸ Hinweise


KI-generierte Inhalte mÃ¼ssen kenntlich gemacht werden
Studienoutputs brauchen mehrstufige QS (Pilot, Review, Archivierung)
Validierung â‰  Wahrheit â†’ Modul liefert belastbare Wahrscheinlichkeiten, keine Beweise

---
modul: M14
title: Validierung & QualitÃ¤tssicherung
author: Sebastian Besold / GPT-4o
version: 1.0
linked_modules: [M1, M9, M11, M12]
tools: [redundanztest, peer_review, checklists, feedbacklog]
license: CC BY 4.0
last_updated: 2025-08-07
---
